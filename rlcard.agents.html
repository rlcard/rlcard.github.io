

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>rlcard.agents &mdash; RLcard 0.0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="static/documentation_options.js"></script>
        <script type="text/javascript" src="static/jquery.js"></script>
        <script type="text/javascript" src="static/underscore.js"></script>
        <script type="text/javascript" src="static/doctools.js"></script>
        <script type="text/javascript" src="static/language_data.js"></script>
    
    <script type="text/javascript" src="static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <!-- <link rel="copyright" title="DATA Lab at Texas A&M University"> -->
    <link rel="next" title="rlcard.core" href="rlcard.core.html" />
    <link rel="prev" title="rlcard.games.simpledoudizhu" href="rlcard.games.simpledoudizhu.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
          <a href="index.html" style="margin: 0px;"><img src="static/imgs/logo_white.png" style="height: initial; width: initial; border-radius: initial; margin: 0px;" alt="home"></a>
          

          
          </a>

          
            
            
          

          
<div role="search" id="test-search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Documentation:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="overview.html#design-principles">Design Principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="overview.html#rlcard-high-level-design">RLCard High-level Design</a><ul>
<li class="toctree-l3"><a class="reference internal" href="overview.html#environments">Environments</a></li>
<li class="toctree-l3"><a class="reference internal" href="overview.html#games">Games</a></li>
<li class="toctree-l3"><a class="reference internal" href="overview.html#agents">Agents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="getting_started.html#playing-with-random-agents">Playing with Random Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting_started.html#deep-q-learning-on-blackjack">Deep-Q Learning on Blackjack</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting_started.html#training-cfr-on-leduc-hold-em">Training CFR on Leduc Hold’em</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting_started.html#having-fun-with-pretrained-leduc-model">Having Fun with Pretrained Leduc Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting_started.html#leduc-hold-em-as-single-agent-environment">Leduc Hold’em as Single-Agent Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting_started.html#running-multiple-processes">Running Multiple Processes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="games.html">Games in RLCard</a><ul>
<li class="toctree-l2"><a class="reference internal" href="games.html#blackjack">Blackjack</a><ul>
<li class="toctree-l3"><a class="reference internal" href="games.html#state-representation-of-blackjack">State Representation of Blackjack</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#action-encoding-of-blackjack">Action Encoding of Blackjack</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#payoff-of-blackjack">Payoff of Blackjack</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="games.html#leduc-hold-em">Leduc Hold’em</a><ul>
<li class="toctree-l3"><a class="reference internal" href="games.html#state-representation-of-leduc-hold-em">State Representation of Leduc Hold’em</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#action-encoding-of-leduc-hold-em">Action Encoding of Leduc Hold’em</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#payoff-of-leduc-hold-em">Payoff of Leduc Hold’em</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="games.html#limit-texas-hold-em">Limit Texas Hold’em</a><ul>
<li class="toctree-l3"><a class="reference internal" href="games.html#state-representation-of-limit-texas-hold-em">State Representation of Limit Texas Hold’em</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#action-encoding-of-limit-texas-hold-em">Action Encoding of Limit Texas Hold’em</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#payoff-of-limit-texas-hold-em">Payoff of Limit Texas Hold’em</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="games.html#dou-dizhu">Dou Dizhu</a><ul>
<li class="toctree-l3"><a class="reference internal" href="games.html#state-representation-of-dou-dizhu">State Representation of Dou Dizhu</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#state-encoding-of-dou-dizhu">State Encoding of Dou Dizhu</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#action-abstraction-of-dou-dizhu">Action Abstraction of Dou Dizhu</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#payoff">Payoff</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="games.html#mahjong">Mahjong</a><ul>
<li class="toctree-l3"><a class="reference internal" href="games.html#state-representation-of-mahjong">State Representation of Mahjong</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#action-space-of-mahjong">Action Space of Mahjong</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#payoff-of-mahjong">Payoff of Mahjong</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="games.html#no-limit-texas-hold-em">No-limit Texas Hold’em</a><ul>
<li class="toctree-l3"><a class="reference internal" href="games.html#state-representation-of-no-limit-texas-hold-em">State Representation of No-Limit Texas Hold’em</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#action-encoding-of-no-limit-texas-hold-em">Action Encoding of No-Limit Texas Hold’em</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#payoff-of-no-limit-texas-hold-em">Payoff of No-Limit Texas Hold’em</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="games.html#uno">UNO</a><ul>
<li class="toctree-l3"><a class="reference internal" href="games.html#state-representation-of-uno">State Representation of Uno</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#state-encoding-of-uno">State Encoding of Uno</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#action-encoding-of-uno">Action Encoding of Uno</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#payoff-of-uno">Payoff of Uno</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="games.html#gin-rummy">Gin Rummy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="games.html#state-representation-of-gin-rummy">State Representation of Gin Rummy</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#action-space-of-gin-rummy">Action Space of Gin Rummy</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#payoff-of-gin-rummy">Payoff of Gin Rummy</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#settings">Settings</a></li>
<li class="toctree-l3"><a class="reference internal" href="games.html#variations">Variations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="algorithms.html">Algorithms</a><ul>
<li class="toctree-l2"><a class="reference internal" href="algorithms.html#deep-q-learning">Deep-Q Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="algorithms.html#nfsp">NFSP</a></li>
<li class="toctree-l2"><a class="reference internal" href="algorithms.html#cfr">CFR</a></li>
<li class="toctree-l2"><a class="reference internal" href="algorithms.html#deepcfr">DeepCFR</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="development.html">Development</a><ul>
<li class="toctree-l2"><a class="reference internal" href="development.html#adding-pre-trained-rule-based-models">Adding Pre-trained/Rule-based models</a></li>
<li class="toctree-l2"><a class="reference internal" href="development.html#developping-algorithms">Developping Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="development.html#adding-new-environments">Adding New Environments</a></li>
<li class="toctree-l2"><a class="reference internal" href="development.html#customizing-environments">Customizing Environments</a><ul>
<li class="toctree-l3"><a class="reference internal" href="development.html#state-representation">State Representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="development.html#action-encoding">Action Encoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="development.html#reward-calculation">Reward Calculation</a></li>
<li class="toctree-l3"><a class="reference internal" href="development.html#modifying-game">Modifying Game</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">API Documents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="rlcard.envs.html">rlcard.envs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="rlcard.envs.html#module-rlcard.envs.env">rlcard.envs.env</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.envs.html#module-rlcard.envs.registration">rlcard.envs.registration</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.envs.html#module-rlcard.envs.blackjack">rlcard.envs.blackjack</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.envs.html#module-rlcard.envs.doudizhu">rlcard.envs.doudizhu</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.envs.html#module-rlcard.envs.limitholdem">rlcard.envs.limitholdem</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.envs.html#module-rlcard.envs.gin_rummy">rlcard.envs.gin_rummy</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.envs.html#module-rlcard.envs.leducholdem">rlcard.envs.leducholdem</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.envs.html#module-rlcard.envs.mahjong">rlcard.envs.mahjong</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.envs.html#module-rlcard.envs.nolimitholdem">rlcard.envs.nolimitholdem</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.envs.html#module-rlcard.envs.simpledoudizhu">rlcard.envs.simpledoudizhu</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.envs.html#module-rlcard.envs.uno">rlcard.envs.uno</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="rlcard.utils.html">rlcard.utils</a><ul>
<li class="toctree-l2"><a class="reference internal" href="rlcard.utils.html#module-rlcard.utils.utils">rlcard.utils.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.utils.html#module-rlcard.utils.logger">rlcard.utils.logger</a></li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.utils.html#module-rlcard.utils.exploitability">rlcard.utils.exploitability</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="rlcard.games.html">rlcard.games</a><ul>
<li class="toctree-l2"><a class="reference internal" href="rlcard.games.blackjack.html">rlcard.games.blackjack</a><ul>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.blackjack.html#module-rlcard.games.blackjack.dealer">rlcard.games.blackjack.dealer</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.blackjack.html#module-rlcard.games.blackjack.game">rlcard.games.blackjack.game</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.blackjack.html#module-rlcard.games.blackjack.judger">rlcard.games.blackjack.judger</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.blackjack.html#module-rlcard.games.blackjack.player">rlcard.games.blackjack.player</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.games.doudizhu.html">rlcard.games.doudizhu</a><ul>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.doudizhu.html#module-rlcard.games.doudizhu.dealer">rlcard.games.doudizhu.dealer</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.doudizhu.html#module-rlcard.games.doudizhu.game">rlcard.games.doudizhu.game</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.doudizhu.html#module-rlcard.games.doudizhu.judger">rlcard.games.doudizhu.judger</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.doudizhu.html#module-rlcard.games.doudizhu.player">rlcard.games.doudizhu.player</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.doudizhu.html#module-rlcard.games.doudizhu.round">rlcard.games.doudizhu.round</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.games.limitholdem.html">rlcard.games.limitholdem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.limitholdem.html#module-rlcard.games.limitholdem.dealer">rlcard.games.limitholdem.dealer</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.limitholdem.html#module-rlcard.games.limitholdem.game">rlcard.games.limitholdem.game</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.limitholdem.html#module-rlcard.games.limitholdem.judger">rlcard.games.limitholdem.judger</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.limitholdem.html#module-rlcard.games.limitholdem.player">rlcard.games.limitholdem.player</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.limitholdem.html#module-rlcard.games.limitholdem.round">rlcard.games.limitholdem.round</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.limitholdem.html#module-rlcard.games.limitholdem.utils">rlcard.games.limitholdem.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.games.nolimitholdem.html">rlcard.games.nolimitholdem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.nolimitholdem.html#module-rlcard.games.nolimitholdem.dealer">rlcard.games.nolimitholdem.dealer</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.nolimitholdem.html#module-rlcard.games.nolimitholdem.game">rlcard.games.nolimitholdem.game</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.nolimitholdem.html#module-rlcard.games.nolimitholdem.judger">rlcard.games.nolimitholdem.judger</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.nolimitholdem.html#module-rlcard.games.nolimitholdem.player">rlcard.games.nolimitholdem.player</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.nolimitholdem.html#module-rlcard.games.nolimitholdem.round">rlcard.games.nolimitholdem.round</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.games.leducholdem.html">rlcard.games.leducholdem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.leducholdem.html#module-rlcard.games.leducholdem.dealer">rlcard.games.leducholdem.dealer</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.leducholdem.html#module-rlcard.games.leducholdem.game">rlcard.games.leducholdem.game</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.leducholdem.html#module-rlcard.games.leducholdem.judger">rlcard.games.leducholdem.judger</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.leducholdem.html#module-rlcard.games.leducholdem.player">rlcard.games.leducholdem.player</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.leducholdem.html#module-rlcard.games.leducholdem.round">rlcard.games.leducholdem.round</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.games.uno.html">rlcard.games.uno</a><ul>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.uno.html#module-rlcard.games.uno.dealer">rlcard.games.uno.dealer</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.uno.html#module-rlcard.games.uno.game">rlcard.games.uno.game</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.uno.html#module-rlcard.games.uno.judger">rlcard.games.uno.judger</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.uno.html#module-rlcard.games.uno.player">rlcard.games.uno.player</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.uno.html#module-rlcard.games.uno.round">rlcard.games.uno.round</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.uno.html#module-rlcard.games.uno.card">rlcard.games.uno.card</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.uno.html#module-rlcard.games.uno.utils">rlcard.games.uno.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.games.mahjong.html">rlcard.games.mahjong</a><ul>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.mahjong.html#module-rlcard.games.mahjong.dealer">rlcard.games.mahjong.dealer</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.mahjong.html#module-rlcard.games.mahjong.game">rlcard.games.mahjong.game</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.mahjong.html#module-rlcard.games.mahjong.judger">rlcard.games.mahjong.judger</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.mahjong.html#module-rlcard.games.mahjong.player">rlcard.games.mahjong.player</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.mahjong.html#module-rlcard.games.mahjong.round">rlcard.games.mahjong.round</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.mahjong.html#module-rlcard.games.mahjong.card">rlcard.games.mahjong.card</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.mahjong.html#module-rlcard.games.mahjong.utils">rlcard.games.mahjong.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.games.gin_rummy.html">rlcard.games.gin_rummy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.gin_rummy.utils.html">rlcard.games.gin_rummy.utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="rlcard.games.gin_rummy.utils.html#module-rlcard.games.gin_rummy.utils.action_event">rlcard.games.gin_rummy.utils.action_event</a></li>
<li class="toctree-l4"><a class="reference internal" href="rlcard.games.gin_rummy.utils.html#module-rlcard.games.gin_rummy.utils.melding">rlcard.games.gin_rummy.utils.melding</a></li>
<li class="toctree-l4"><a class="reference internal" href="rlcard.games.gin_rummy.utils.html#module-rlcard.games.gin_rummy.utils.move">rlcard.games.gin_rummy.utils.move</a></li>
<li class="toctree-l4"><a class="reference internal" href="rlcard.games.gin_rummy.utils.html#module-rlcard.games.gin_rummy.utils.scorers">rlcard.games.gin_rummy.utils.scorers</a></li>
<li class="toctree-l4"><a class="reference internal" href="rlcard.games.gin_rummy.utils.html#module-rlcard.games.gin_rummy.utils.settings">rlcard.games.gin_rummy.utils.settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="rlcard.games.gin_rummy.utils.html#module-rlcard.games.gin_rummy.utils.utils">rlcard.games.gin_rummy.utils.utils</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.gin_rummy.html#module-rlcard.games.gin_rummy.dealer">rlcard.games.gin_rummy.dealer</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.gin_rummy.html#module-rlcard.games.gin_rummy.game">rlcard.games.gin_rummy.game</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.gin_rummy.html#module-rlcard.games.gin_rummy.judge">rlcard.games.gin_rummy.judge</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.gin_rummy.html#module-rlcard.games.gin_rummy.player">rlcard.games.gin_rummy.player</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.gin_rummy.html#module-rlcard.games.gin_rummy.round">rlcard.games.gin_rummy.round</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="rlcard.games.simpledoudizhu.html">rlcard.games.simpledoudizhu</a><ul>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.simpledoudizhu.html#module-rlcard.games.simpledoudizhu.dealer">rlcard.games.simpledoudizhu.dealer</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.simpledoudizhu.html#module-rlcard.games.simpledoudizhu.game">rlcard.games.simpledoudizhu.game</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.simpledoudizhu.html#module-rlcard.games.simpledoudizhu.player">rlcard.games.simpledoudizhu.player</a></li>
<li class="toctree-l3"><a class="reference internal" href="rlcard.games.simpledoudizhu.html#module-rlcard.games.simpledoudizhu.round">rlcard.games.simpledoudizhu.round</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">rlcard.agents</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-rlcard.agents.best_response_agent">rlcard.agents.best_response_agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-rlcard.agents.cfr_agent">rlcard.agents.cfr_agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-rlcard.agents.deep_cfr_agent">rlcard.agents.deep_cfr_agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-rlcard.agents.dqn_agent">rlcard.agents.dqn_agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-rlcard.agents.nfsp_agent">rlcard.agents.nfsp_agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-rlcard.agents.random_agent">rlcard.agents.random_agent</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="rlcard.core.html">rlcard.core</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="doctree.html">RLcard</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div style="display: flex; justify-content: space-between">
  <div role="navigation" aria-label="breadcrumbs navigation">

    <ul class="wy-breadcrumbs" style="margin-top: 0.3rem;">
      
        <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          
        <li>RLCard: A Toolkit for Reinforcement Learning in Card Games</li>
      
    </ul>

    
  </div>
  <div style="display: block; width: 7.5rem; max-width: 7.5rem; padding-right: .6rem; float: right;">
    <a href="https://github.com/datamllab/rlcard" title="Go to repository" data-md-source="github" data-md-state="done" style="display: block; padding-right: .6rem; line-height: 1.2">
      <div style="display: inline-block; width: 2.4rem; height: 2.4rem;">
        <i class="fa fa-github" style="font-size: 2rem"></i>  
      </div>
      <div style="display: inline-block; margin-left: -2rem; margin-top: -0.6rem; padding-left: 2rem; vertical-align: middle">
        GitHub
        <ul style="font-size: 0.7rem; list-style-type: none;"><li style="float: left" id="github-stars">... Stars</li></ul>
      </div>
      <script>
        $(document).ready(function(){
        $.ajax({ url: "https://api.github.com/repos/datamllab/rlcard",
                context: document.body,
                success: function(response){
                  console.log(response.stargazers_count);
                  $("#github-stars").html(response.stargazers_count + ' Stars');
                }});
        });
      </script>
    </a>
  </div>
</div>
<hr/>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="rlcard-agents">
<h1>rlcard.agents<a class="headerlink" href="#rlcard-agents" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-rlcard.agents.best_response_agent">
<span id="rlcard-agents-best-response-agent"></span><h2>rlcard.agents.best_response_agent<a class="headerlink" href="#module-rlcard.agents.best_response_agent" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="rlcard.agents.best_response_agent.BRAgent">
<em class="property">class </em><code class="sig-prename descclassname">rlcard.agents.best_response_agent.</code><code class="sig-name descname">BRAgent</code><span class="sig-paren">(</span><em class="sig-param">env</em>, <em class="sig-param">policy</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.best_response_agent.BRAgent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Implement CFR algorithm</p>
<dl class="method">
<dt id="rlcard.agents.best_response_agent.BRAgent.action_probs">
<code class="sig-name descname">action_probs</code><span class="sig-paren">(</span><em class="sig-param">state</em>, <em class="sig-param">policy</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.best_response_agent.BRAgent.action_probs" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtain the action probabilities of the current state</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state</strong> (<em>dictionaty</em>) – The state dictionary</p></li>
<li><p><strong>policy</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – The used policy</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>action_probs(numpy.array): The action probabilities
legal_actions (list): Indices of legal actions</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)">tuple</a>) that contains</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.best_response_agent.BRAgent.best_response_action">
<code class="sig-name descname">best_response_action</code><span class="sig-paren">(</span><em class="sig-param">this_player</em>, <em class="sig-param">obs</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.best_response_agent.BRAgent.best_response_action" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="rlcard.agents.best_response_agent.BRAgent.eval_step">
<code class="sig-name descname">eval_step</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.best_response_agent.BRAgent.eval_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a state, predict action based on average policy</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<em>numpy.array</em>) – State representation</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Predicted action</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>action (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)">int</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.best_response_agent.BRAgent.get_q_value">
<code class="sig-name descname">get_q_value</code><span class="sig-paren">(</span><em class="sig-param">action</em>, <em class="sig-param">q_value</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.best_response_agent.BRAgent.get_q_value" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="rlcard.agents.best_response_agent.BRAgent.get_state">
<code class="sig-name descname">get_state</code><span class="sig-paren">(</span><em class="sig-param">player_id</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.best_response_agent.BRAgent.get_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get state_str of the player</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>player_id</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The player id</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>state (str): The state str
legal_actions (list): Indices of legal actions</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)">tuple</a>) that contains</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.best_response_agent.BRAgent.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.best_response_agent.BRAgent.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load model</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.best_response_agent.BRAgent.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.best_response_agent.BRAgent.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save model</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.best_response_agent.BRAgent.traverse_tree">
<code class="sig-name descname">traverse_tree</code><span class="sig-paren">(</span><em class="sig-param">probs</em>, <em class="sig-param">player_id</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.best_response_agent.BRAgent.traverse_tree" title="Permalink to this definition">¶</a></dt>
<dd><p>Traverse the game tree, get information set</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>probs</strong> – The reach probability of the current node</p></li>
<li><p><strong>player_id</strong> – The player to update the value</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The expected utilities for all the players</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>state_utilities (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.8)">list</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.best_response_agent.BRAgent.value">
<code class="sig-name descname">value</code><span class="sig-paren">(</span><em class="sig-param">curr_player</em>, <em class="sig-param">state</em>, <em class="sig-param">this_player</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.best_response_agent.BRAgent.value" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the value of the specified state to the best-responder.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-rlcard.agents.cfr_agent">
<span id="rlcard-agents-cfr-agent"></span><h2>rlcard.agents.cfr_agent<a class="headerlink" href="#module-rlcard.agents.cfr_agent" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="rlcard.agents.cfr_agent.CFRAgent">
<em class="property">class </em><code class="sig-prename descclassname">rlcard.agents.cfr_agent.</code><code class="sig-name descname">CFRAgent</code><span class="sig-paren">(</span><em class="sig-param">env</em>, <em class="sig-param">model_path='./cfr_model'</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.cfr_agent.CFRAgent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Implement CFR algorithm</p>
<dl class="method">
<dt id="rlcard.agents.cfr_agent.CFRAgent.action_probs">
<code class="sig-name descname">action_probs</code><span class="sig-paren">(</span><em class="sig-param">obs</em>, <em class="sig-param">legal_actions</em>, <em class="sig-param">policy</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.cfr_agent.CFRAgent.action_probs" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtain the action probabilities of the current state</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – state_str</p></li>
<li><p><strong>legal_actions</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – List of leagel actions</p></li>
<li><p><strong>player_id</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The current player</p></li>
<li><p><strong>policy</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – The used policy</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>action_probs(numpy.array): The action probabilities
legal_actions (list): Indices of legal actions</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)">tuple</a>) that contains</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.cfr_agent.CFRAgent.eval_step">
<code class="sig-name descname">eval_step</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.cfr_agent.CFRAgent.eval_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a state, predict action based on average policy</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<em>numpy.array</em>) – State representation</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Predicted action</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>action (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)">int</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.cfr_agent.CFRAgent.get_state">
<code class="sig-name descname">get_state</code><span class="sig-paren">(</span><em class="sig-param">player_id</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.cfr_agent.CFRAgent.get_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get state_str of the player</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>player_id</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The player id</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>state (str): The state str
legal_actions (list): Indices of legal actions</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)">tuple</a>) that contains</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.cfr_agent.CFRAgent.load">
<code class="sig-name descname">load</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.cfr_agent.CFRAgent.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load model</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.cfr_agent.CFRAgent.regret_matching">
<code class="sig-name descname">regret_matching</code><span class="sig-paren">(</span><em class="sig-param">obs</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.cfr_agent.CFRAgent.regret_matching" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply regret matching</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>obs</strong> (<em>string</em>) – The state_str</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.cfr_agent.CFRAgent.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.cfr_agent.CFRAgent.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save model</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.cfr_agent.CFRAgent.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.cfr_agent.CFRAgent.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Do one iteration of CFR</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.cfr_agent.CFRAgent.traverse_tree">
<code class="sig-name descname">traverse_tree</code><span class="sig-paren">(</span><em class="sig-param">probs</em>, <em class="sig-param">player_id</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.cfr_agent.CFRAgent.traverse_tree" title="Permalink to this definition">¶</a></dt>
<dd><p>Traverse the game tree, update the regrets</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>probs</strong> – The reach probability of the current node</p></li>
<li><p><strong>player_id</strong> – The player to update the value</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The expected utilities for all the players</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>state_utilities (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.8)">list</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.cfr_agent.CFRAgent.update_policy">
<code class="sig-name descname">update_policy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.cfr_agent.CFRAgent.update_policy" title="Permalink to this definition">¶</a></dt>
<dd><p>Update policy based on the current regrets</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-rlcard.agents.deep_cfr_agent">
<span id="rlcard-agents-deep-cfr-agent"></span><h2>rlcard.agents.deep_cfr_agent<a class="headerlink" href="#module-rlcard.agents.deep_cfr_agent" title="Permalink to this headline">¶</a></h2>
<p>Implements Deep CFR Algorithm.</p>
<dl class="simple">
<dt>The implementation is derived from:</dt><dd><p><a class="reference external" href="https://github.com/deepmind/open_spiel/blob/master/open_spiel/python/algorithms/deep_cfr.py">https://github.com/deepmind/open_spiel/blob/master/open_spiel/python/algorithms/deep_cfr.py</a></p>
</dd>
</dl>
<p>We modify the structure for single player game and rlcard package, and fix some bugs for loss calculation.</p>
<p>See <a class="reference external" href="https://arxiv.org/abs/1811.00164">https://arxiv.org/abs/1811.00164</a>.</p>
<p>The algorithm defines an <cite>advantage</cite> and <cite>strategy</cite> networks that compute
advantages used to do regret matching across information sets and to approximate
the strategy profiles of the game.    To train these networks a fixed ring buffer
(other data structures may be used) memory is used to accumulate samples to
train the networks.</p>
<dl class="class">
<dt id="rlcard.agents.deep_cfr_agent.AdvantageMemory">
<em class="property">class </em><code class="sig-prename descclassname">rlcard.agents.deep_cfr_agent.</code><code class="sig-name descname">AdvantageMemory</code><span class="sig-paren">(</span><em class="sig-param">info_state</em>, <em class="sig-param">iteration</em>, <em class="sig-param">advantage</em>, <em class="sig-param">action</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.AdvantageMemory" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<dl class="method">
<dt id="rlcard.agents.deep_cfr_agent.AdvantageMemory.action">
<em class="property">property </em><code class="sig-name descname">action</code><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.AdvantageMemory.action" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.deep_cfr_agent.AdvantageMemory.advantage">
<em class="property">property </em><code class="sig-name descname">advantage</code><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.AdvantageMemory.advantage" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.deep_cfr_agent.AdvantageMemory.info_state">
<em class="property">property </em><code class="sig-name descname">info_state</code><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.AdvantageMemory.info_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.deep_cfr_agent.AdvantageMemory.iteration">
<em class="property">property </em><code class="sig-name descname">iteration</code><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.AdvantageMemory.iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rlcard.agents.deep_cfr_agent.DeepCFR">
<em class="property">class </em><code class="sig-prename descclassname">rlcard.agents.deep_cfr_agent.</code><code class="sig-name descname">DeepCFR</code><span class="sig-paren">(</span><em class="sig-param">session</em>, <em class="sig-param">env</em>, <em class="sig-param">policy_network_layers=(32</em>, <em class="sig-param">32)</em>, <em class="sig-param">advantage_network_layers=(32</em>, <em class="sig-param">32)</em>, <em class="sig-param">num_traversals=10</em>, <em class="sig-param">num_step=40</em>, <em class="sig-param">learning_rate=0.0001</em>, <em class="sig-param">batch_size_advantage=16</em>, <em class="sig-param">batch_size_strategy=16</em>, <em class="sig-param">memory_capacity=10000000</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.DeepCFR" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Implement the Deep CFR Algorithm.</p>
<p>See <a class="reference external" href="https://arxiv.org/abs/1811.00164">https://arxiv.org/abs/1811.00164</a>.</p>
<p>Define all networks and sampling buffers/memories.    Derive losses &amp; learning
steps. Initialize the game state and algorithmic variables.</p>
<dl class="simple">
<dt>Note: batch sizes default to <cite>None</cite> implying that training over the full</dt><dd><p>dataset in memory is done by default.    To sample from the memories you
may set these values to something less than the full capacity of the
memory.</p>
</dd>
</dl>
<dl class="method">
<dt id="rlcard.agents.deep_cfr_agent.DeepCFR.action_advantage">
<code class="sig-name descname">action_advantage</code><span class="sig-paren">(</span><em class="sig-param">state</em>, <em class="sig-param">player</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.DeepCFR.action_advantage" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns action advantages for a single batch.</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.deep_cfr_agent.DeepCFR.action_probabilities">
<code class="sig-name descname">action_probabilities</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.DeepCFR.action_probabilities" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns action probabilites dict for a single batch.</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.deep_cfr_agent.DeepCFR.eval_step">
<code class="sig-name descname">eval_step</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.DeepCFR.eval_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the action given state for evaluation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – current state</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>an action id</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>action (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)">int</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.deep_cfr_agent.DeepCFR.reinitialize_advantage_networks">
<code class="sig-name descname">reinitialize_advantage_networks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.DeepCFR.reinitialize_advantage_networks" title="Permalink to this definition">¶</a></dt>
<dd><p>Reinitialize the advantage networks</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.deep_cfr_agent.DeepCFR.simulate_other">
<code class="sig-name descname">simulate_other</code><span class="sig-paren">(</span><em class="sig-param">player</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.DeepCFR.simulate_other" title="Permalink to this definition">¶</a></dt>
<dd><p>Simulate the action for other players</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>player</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – an player id</p></li>
<li><p><strong>state</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – current state</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>an action id</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>action (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)">int</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.deep_cfr_agent.DeepCFR.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.DeepCFR.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform tree traversal and train the network</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the trained policy network
average advantage loss (float): players average advantage loss
policy loss (float): policy loss</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>policy_network (tf.placeholder)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rlcard.agents.deep_cfr_agent.FixedSizeRingBuffer">
<em class="property">class </em><code class="sig-prename descclassname">rlcard.agents.deep_cfr_agent.</code><code class="sig-name descname">FixedSizeRingBuffer</code><span class="sig-paren">(</span><em class="sig-param">replay_buffer_capacity</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.FixedSizeRingBuffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>ReplayBuffer of fixed size with a FIFO replacement policy.</p>
<p>Stored transitions can be sampled uniformly.</p>
<p>The underlying datastructure is a ring buffer, allowing 0(1) adding and
sampling.</p>
<dl class="method">
<dt id="rlcard.agents.deep_cfr_agent.FixedSizeRingBuffer.add">
<code class="sig-name descname">add</code><span class="sig-paren">(</span><em class="sig-param">element</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.FixedSizeRingBuffer.add" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds <cite>element</cite> to the buffer.</p>
<p>If the buffer is full, the oldest element will be replaced.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>element</strong> – data to be added to the buffer.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.deep_cfr_agent.FixedSizeRingBuffer.clear">
<code class="sig-name descname">clear</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.FixedSizeRingBuffer.clear" title="Permalink to this definition">¶</a></dt>
<dd><p>Clear the buffer</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.deep_cfr_agent.FixedSizeRingBuffer.sample">
<code class="sig-name descname">sample</code><span class="sig-paren">(</span><em class="sig-param">num_samples</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.FixedSizeRingBuffer.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns <cite>num_samples</cite> uniformly sampled from the buffer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>num_samples</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – number of samples to draw.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a list of random sampled elements of the buffer</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>sample data (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.8)">list</a>)</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If there are less than <cite>num_samples</cite> elements in the buffer</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rlcard.agents.deep_cfr_agent.StrategyMemory">
<em class="property">class </em><code class="sig-prename descclassname">rlcard.agents.deep_cfr_agent.</code><code class="sig-name descname">StrategyMemory</code><span class="sig-paren">(</span><em class="sig-param">info_state</em>, <em class="sig-param">iteration</em>, <em class="sig-param">strategy_action_probs</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.StrategyMemory" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<dl class="method">
<dt id="rlcard.agents.deep_cfr_agent.StrategyMemory.info_state">
<em class="property">property </em><code class="sig-name descname">info_state</code><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.StrategyMemory.info_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.deep_cfr_agent.StrategyMemory.iteration">
<em class="property">property </em><code class="sig-name descname">iteration</code><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.StrategyMemory.iteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.deep_cfr_agent.StrategyMemory.strategy_action_probs">
<em class="property">property </em><code class="sig-name descname">strategy_action_probs</code><a class="headerlink" href="#rlcard.agents.deep_cfr_agent.StrategyMemory.strategy_action_probs" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-rlcard.agents.dqn_agent">
<span id="rlcard-agents-dqn-agent"></span><h2>rlcard.agents.dqn_agent<a class="headerlink" href="#module-rlcard.agents.dqn_agent" title="Permalink to this headline">¶</a></h2>
<p>DQN agent</p>
<p>The code is derived from <a class="reference external" href="https://github.com/dennybritz/reinforcement-learning/blob/master/DQN/dqn.py">https://github.com/dennybritz/reinforcement-learning/blob/master/DQN/dqn.py</a></p>
<p>Copyright (c) 2019 DATA Lab at Texas A&amp;M University
Copyright (c) 2016 Denny Britz</p>
<p>Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the “Software”), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:</p>
<p>The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.</p>
<p>THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.</p>
<dl class="class">
<dt id="rlcard.agents.dqn_agent.DQNAgent">
<em class="property">class </em><code class="sig-prename descclassname">rlcard.agents.dqn_agent.</code><code class="sig-name descname">DQNAgent</code><span class="sig-paren">(</span><em class="sig-param">sess</em>, <em class="sig-param">scope</em>, <em class="sig-param">replay_memory_size=20000</em>, <em class="sig-param">replay_memory_init_size=100</em>, <em class="sig-param">update_target_estimator_every=1000</em>, <em class="sig-param">discount_factor=0.99</em>, <em class="sig-param">epsilon_start=1.0</em>, <em class="sig-param">epsilon_end=0.1</em>, <em class="sig-param">epsilon_decay_steps=20000</em>, <em class="sig-param">batch_size=32</em>, <em class="sig-param">action_num=2</em>, <em class="sig-param">state_shape=None</em>, <em class="sig-param">train_every=1</em>, <em class="sig-param">mlp_layers=None</em>, <em class="sig-param">learning_rate=5e-05</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.dqn_agent.DQNAgent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<dl class="method">
<dt id="rlcard.agents.dqn_agent.DQNAgent.copy_params_op">
<code class="sig-name descname">copy_params_op</code><span class="sig-paren">(</span><em class="sig-param">global_vars</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.dqn_agent.DQNAgent.copy_params_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Copys the variables of two estimator to others.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>global_vars</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – A list of tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.dqn_agent.DQNAgent.eval_step">
<code class="sig-name descname">eval_step</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.dqn_agent.DQNAgent.eval_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the action for evaluation purpose.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<em>numpy.array</em>) – current state</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>an action id
probs (list): a list of probabilies</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>action (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)">int</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.dqn_agent.DQNAgent.feed">
<code class="sig-name descname">feed</code><span class="sig-paren">(</span><em class="sig-param">ts</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.dqn_agent.DQNAgent.feed" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Store data in to replay buffer and train the agent. There are two stages.</dt><dd><p>In stage 1, populate the memory without training
In stage 2, train the agent every several timesteps</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>ts</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – a list of 5 elements that represent the transition</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.dqn_agent.DQNAgent.feed_memory">
<code class="sig-name descname">feed_memory</code><span class="sig-paren">(</span><em class="sig-param">state</em>, <em class="sig-param">action</em>, <em class="sig-param">reward</em>, <em class="sig-param">next_state</em>, <em class="sig-param">done</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.dqn_agent.DQNAgent.feed_memory" title="Permalink to this definition">¶</a></dt>
<dd><p>Feed transition to memory</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state</strong> (<em>numpy.array</em>) – the current state</p></li>
<li><p><strong>action</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – the performed action ID</p></li>
<li><p><strong>reward</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – the reward received</p></li>
<li><p><strong>next_state</strong> (<em>numpy.array</em>) – the next state after performing the action</p></li>
<li><p><strong>done</strong> (<em>boolean</em>) – whether the episode is finished</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.dqn_agent.DQNAgent.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.dqn_agent.DQNAgent.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the action probabilities</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<em>numpy.array</em>) – current state</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a 1-d array where each entry represents a Q value</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>q_values (numpy.array)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.dqn_agent.DQNAgent.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.dqn_agent.DQNAgent.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the action for genrating training data</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<em>numpy.array</em>) – current state</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>an action id</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>action (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)">int</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.dqn_agent.DQNAgent.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.dqn_agent.DQNAgent.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Train the network</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The loss of the current batch.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>loss (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)">float</a>)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rlcard.agents.dqn_agent.Estimator">
<em class="property">class </em><code class="sig-prename descclassname">rlcard.agents.dqn_agent.</code><code class="sig-name descname">Estimator</code><span class="sig-paren">(</span><em class="sig-param">scope='estimator'</em>, <em class="sig-param">action_num=2</em>, <em class="sig-param">learning_rate=0.001</em>, <em class="sig-param">state_shape=None</em>, <em class="sig-param">mlp_layers=None</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.dqn_agent.Estimator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Q-Value Estimator neural network.
This network is used for both the Q-Network and the Target Network.</p>
<dl class="method">
<dt id="rlcard.agents.dqn_agent.Estimator.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">sess</em>, <em class="sig-param">s</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.dqn_agent.Estimator.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts action values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sess</strong> (<em>tf.Session</em>) – Tensorflow Session object</p></li>
<li><p><strong>s</strong> (<em>numpy.array</em>) – State input of shape [batch_size, 4, 160, 160, 3]</p></li>
<li><p><strong>is_train</strong> (<em>boolean</em>) – True if is training</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor of shape [batch_size, NUM_VALID_ACTIONS] containing the estimated
action values.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.dqn_agent.Estimator.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param">sess</em>, <em class="sig-param">s</em>, <em class="sig-param">a</em>, <em class="sig-param">y</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.dqn_agent.Estimator.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the estimator towards the given targets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sess</strong> (<em>tf.Session</em>) – Tensorflow Session object</p></li>
<li><p><strong>s</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – State input of shape [batch_size, 4, 160, 160, 3]</p></li>
<li><p><strong>a</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – Chosen actions of shape [batch_size]</p></li>
<li><p><strong>y</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – Targets of shape [batch_size]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The calculated loss on the batch.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rlcard.agents.dqn_agent.Memory">
<em class="property">class </em><code class="sig-prename descclassname">rlcard.agents.dqn_agent.</code><code class="sig-name descname">Memory</code><span class="sig-paren">(</span><em class="sig-param">memory_size</em>, <em class="sig-param">batch_size</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.dqn_agent.Memory" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Memory for saving transitions</p>
<dl class="method">
<dt id="rlcard.agents.dqn_agent.Memory.sample">
<code class="sig-name descname">sample</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.dqn_agent.Memory.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Sample a minibatch from the replay memory</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a batch of states
action_batch (list): a batch of actions
reward_batch (list): a batch of rewards
next_state_batch (list): a batch of states
done_batch (list): a batch of dones</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>state_batch (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.8)">list</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.dqn_agent.Memory.save">
<code class="sig-name descname">save</code><span class="sig-paren">(</span><em class="sig-param">state</em>, <em class="sig-param">action</em>, <em class="sig-param">reward</em>, <em class="sig-param">next_state</em>, <em class="sig-param">done</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.dqn_agent.Memory.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save transition into memory</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state</strong> (<em>numpy.array</em>) – the current state</p></li>
<li><p><strong>action</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – the performed action ID</p></li>
<li><p><strong>reward</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – the reward received</p></li>
<li><p><strong>next_state</strong> (<em>numpy.array</em>) – the next state after performing the action</p></li>
<li><p><strong>done</strong> (<em>boolean</em>) – whether the episode is finished</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rlcard.agents.dqn_agent.Transition">
<em class="property">class </em><code class="sig-prename descclassname">rlcard.agents.dqn_agent.</code><code class="sig-name descname">Transition</code><span class="sig-paren">(</span><em class="sig-param">state</em>, <em class="sig-param">action</em>, <em class="sig-param">reward</em>, <em class="sig-param">next_state</em>, <em class="sig-param">done</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.dqn_agent.Transition" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<dl class="method">
<dt id="rlcard.agents.dqn_agent.Transition.action">
<em class="property">property </em><code class="sig-name descname">action</code><a class="headerlink" href="#rlcard.agents.dqn_agent.Transition.action" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.dqn_agent.Transition.done">
<em class="property">property </em><code class="sig-name descname">done</code><a class="headerlink" href="#rlcard.agents.dqn_agent.Transition.done" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.dqn_agent.Transition.next_state">
<em class="property">property </em><code class="sig-name descname">next_state</code><a class="headerlink" href="#rlcard.agents.dqn_agent.Transition.next_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.dqn_agent.Transition.reward">
<em class="property">property </em><code class="sig-name descname">reward</code><a class="headerlink" href="#rlcard.agents.dqn_agent.Transition.reward" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.dqn_agent.Transition.state">
<em class="property">property </em><code class="sig-name descname">state</code><a class="headerlink" href="#rlcard.agents.dqn_agent.Transition.state" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="rlcard.agents.dqn_agent.copy_model_parameters">
<code class="sig-prename descclassname">rlcard.agents.dqn_agent.</code><code class="sig-name descname">copy_model_parameters</code><span class="sig-paren">(</span><em class="sig-param">sess</em>, <em class="sig-param">estimator1</em>, <em class="sig-param">estimator2</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.dqn_agent.copy_model_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Copys the model parameters of one estimator to another.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sess</strong> (<em>tf.Session</em>) – Tensorflow Session object</p></li>
<li><p><strong>estimator1</strong> (<a class="reference internal" href="#rlcard.agents.dqn_agent.Estimator" title="rlcard.agents.dqn_agent.Estimator"><em>Estimator</em></a>) – Estimator to copy the paramters from</p></li>
<li><p><strong>estimator2</strong> (<a class="reference internal" href="#rlcard.agents.dqn_agent.Estimator" title="rlcard.agents.dqn_agent.Estimator"><em>Estimator</em></a>) – Estimator to copy the parameters to</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-rlcard.agents.nfsp_agent">
<span id="rlcard-agents-nfsp-agent"></span><h2>rlcard.agents.nfsp_agent<a class="headerlink" href="#module-rlcard.agents.nfsp_agent" title="Permalink to this headline">¶</a></h2>
<p>Neural Fictitious Self-Play (NFSP) agent implemented in TensorFlow.</p>
<p>See the paper <a class="reference external" href="https://arxiv.org/abs/1603.01121">https://arxiv.org/abs/1603.01121</a> for more details.</p>
<dl class="attribute">
<dt id="rlcard.agents.nfsp_agent.MODE">
<code class="sig-prename descclassname">rlcard.agents.nfsp_agent.</code><code class="sig-name descname">MODE</code><a class="headerlink" href="#rlcard.agents.nfsp_agent.MODE" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">rlcard.agents.nfsp_agent.mode</span></code></p>
</dd></dl>

<dl class="class">
<dt id="rlcard.agents.nfsp_agent.NFSPAgent">
<em class="property">class </em><code class="sig-prename descclassname">rlcard.agents.nfsp_agent.</code><code class="sig-name descname">NFSPAgent</code><span class="sig-paren">(</span><em class="sig-param">sess</em>, <em class="sig-param">scope</em>, <em class="sig-param">action_num=4</em>, <em class="sig-param">state_shape=None</em>, <em class="sig-param">hidden_layers_sizes=None</em>, <em class="sig-param">reservoir_buffer_capacity=1000000</em>, <em class="sig-param">anticipatory_param=0.1</em>, <em class="sig-param">batch_size=256</em>, <em class="sig-param">train_every=1</em>, <em class="sig-param">rl_learning_rate=0.1</em>, <em class="sig-param">sl_learning_rate=0.005</em>, <em class="sig-param">min_buffer_size_to_learn=1000</em>, <em class="sig-param">q_replay_memory_size=30000</em>, <em class="sig-param">q_replay_memory_init_size=1000</em>, <em class="sig-param">q_update_target_estimator_every=1000</em>, <em class="sig-param">q_discount_factor=0.99</em>, <em class="sig-param">q_epsilon_start=0.06</em>, <em class="sig-param">q_epsilon_end=0</em>, <em class="sig-param">q_epsilon_decay_steps=1000000</em>, <em class="sig-param">q_batch_size=256</em>, <em class="sig-param">q_train_every=1</em>, <em class="sig-param">q_mlp_layers=None</em>, <em class="sig-param">evaluate_with='average_policy'</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.nfsp_agent.NFSPAgent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>NFSP Agent implementation in TensorFlow.</p>
<dl class="method">
<dt id="rlcard.agents.nfsp_agent.NFSPAgent.eval_step">
<code class="sig-name descname">eval_step</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.nfsp_agent.NFSPAgent.eval_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the average policy for evaluation purpose</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – The current state.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An action id.
probs (list): The list of action probabilies</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>action (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)">int</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.nfsp_agent.NFSPAgent.feed">
<code class="sig-name descname">feed</code><span class="sig-paren">(</span><em class="sig-param">ts</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.nfsp_agent.NFSPAgent.feed" title="Permalink to this definition">¶</a></dt>
<dd><p>Feed data to inner RL agent</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>ts</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a>) – A list of 5 elements that represent the transition.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.nfsp_agent.NFSPAgent.sample_episode_policy">
<code class="sig-name descname">sample_episode_policy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.nfsp_agent.NFSPAgent.sample_episode_policy" title="Permalink to this definition">¶</a></dt>
<dd><p>Sample average/best_response policy</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.nfsp_agent.NFSPAgent.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.nfsp_agent.NFSPAgent.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the action to be taken.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – The current state</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An action id</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>action (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)">int</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.nfsp_agent.NFSPAgent.train_sl">
<code class="sig-name descname">train_sl</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.nfsp_agent.NFSPAgent.train_sl" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the loss on sampled transitions and perform a avg-network update.</p>
<p>If there are not enough elements in the buffer, no loss is computed and
<cite>None</cite> is returned instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The average loss obtained on this batch of transitions or <cite>None</cite>.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>loss (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)">float</a>)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rlcard.agents.nfsp_agent.ReservoirBuffer">
<em class="property">class </em><code class="sig-prename descclassname">rlcard.agents.nfsp_agent.</code><code class="sig-name descname">ReservoirBuffer</code><span class="sig-paren">(</span><em class="sig-param">reservoir_buffer_capacity</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.nfsp_agent.ReservoirBuffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Allows uniform sampling over a stream of data.</p>
<p>This class supports the storage of arbitrary elements, such as observation
tensors, integer actions, etc.</p>
<p>See <a class="reference external" href="https://en.wikipedia.org/wiki/Reservoir_sampling">https://en.wikipedia.org/wiki/Reservoir_sampling</a> for more details.</p>
<dl class="method">
<dt id="rlcard.agents.nfsp_agent.ReservoirBuffer.add">
<code class="sig-name descname">add</code><span class="sig-paren">(</span><em class="sig-param">element</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.nfsp_agent.ReservoirBuffer.add" title="Permalink to this definition">¶</a></dt>
<dd><p>Potentially adds <cite>element</cite> to the reservoir buffer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>element</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)"><em>object</em></a>) – data to be added to the reservoir buffer.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.nfsp_agent.ReservoirBuffer.clear">
<code class="sig-name descname">clear</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.nfsp_agent.ReservoirBuffer.clear" title="Permalink to this definition">¶</a></dt>
<dd><p>Clear the buffer</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.nfsp_agent.ReservoirBuffer.sample">
<code class="sig-name descname">sample</code><span class="sig-paren">(</span><em class="sig-param">num_samples</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.nfsp_agent.ReservoirBuffer.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns <cite>num_samples</cite> uniformly sampled from the buffer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>num_samples</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of samples to draw.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An iterable over <cite>num_samples</cite> random elements of the buffer.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.8)"><strong>ValueError</strong></a> – If there are less than <cite>num_samples</cite> elements in the buffer</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="rlcard.agents.nfsp_agent.Transition">
<em class="property">class </em><code class="sig-prename descclassname">rlcard.agents.nfsp_agent.</code><code class="sig-name descname">Transition</code><span class="sig-paren">(</span><em class="sig-param">info_state</em>, <em class="sig-param">action_probs</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.nfsp_agent.Transition" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<dl class="method">
<dt id="rlcard.agents.nfsp_agent.Transition.action_probs">
<em class="property">property </em><code class="sig-name descname">action_probs</code><a class="headerlink" href="#rlcard.agents.nfsp_agent.Transition.action_probs" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.nfsp_agent.Transition.info_state">
<em class="property">property </em><code class="sig-name descname">info_state</code><a class="headerlink" href="#rlcard.agents.nfsp_agent.Transition.info_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-rlcard.agents.random_agent">
<span id="rlcard-agents-random-agent"></span><h2>rlcard.agents.random_agent<a class="headerlink" href="#module-rlcard.agents.random_agent" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="rlcard.agents.random_agent.RandomAgent">
<em class="property">class </em><code class="sig-prename descclassname">rlcard.agents.random_agent.</code><code class="sig-name descname">RandomAgent</code><span class="sig-paren">(</span><em class="sig-param">action_num</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.random_agent.RandomAgent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>A random agent. Random agents is for running toy examples on the card games</p>
<dl class="method">
<dt id="rlcard.agents.random_agent.RandomAgent.eval_step">
<code class="sig-name descname">eval_step</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.random_agent.RandomAgent.eval_step" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Predict the action given the curent state for evaluation.</dt><dd><p>Since the random agents are not trained. This function is equivalent to step function</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – An dictionary that represents the current state</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The action predicted (randomly chosen) by the random agent
probs (list): The list of action probabilities</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>action (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)">int</a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="rlcard.agents.random_agent.RandomAgent.step">
<em class="property">static </em><code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="headerlink" href="#rlcard.agents.random_agent.RandomAgent.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the action given the curent state in gerenerating training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – An dictionary that represents the current state</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The action predicted (randomly chosen) by the random agent</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>action (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)">int</a>)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="rlcard.core.html" class="btn btn-neutral float-right" title="rlcard.core" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="rlcard.games.simpledoudizhu.html" class="btn btn-neutral float-left" title="rlcard.games.simpledoudizhu" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright DATA Lab at Texas A&amp;M University

    </p>
  </div>
    
    
      Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>